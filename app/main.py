# app/main.py
from fastapi import FastAPI
from pydantic import BaseModel
from app.llm import call_llm_domain_ir
from app.render_cnn_matrix import render_cnn_matrix
from app.llm_pseudocode import call_llm_pseudocode_ir
from app.llm_anim_ir import call_llm_anim_ir
from app.llm_codegen import call_llm_codegen
from openai import OpenAI
import os, tempfile, subprocess
from dotenv import load_dotenv
import re

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI(title="GenAI Visualization API")

def sanitize_input_text(text: str) -> str:
    """
    ì‚¬ìš©ìê°€ ë³´ë‚¸ ê¸´ ìì—°ì–´ ì„¤ëª…ì„ JSONìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•˜ê¸° ìœ„í•œ ì „ì²˜ë¦¬ê¸°.
    - ì¤„ë°”ê¿ˆ(\n, \r) â†’ ê³µë°±ìœ¼ë¡œ ë³€í™˜
    - ì—°ì† ê³µë°± ì •ë¦¬
    - ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
    - ì œì–´ ë¬¸ì ì œê±°
    """
    text = text.replace("\r", " ").replace("\n", " ")   # ì¤„ë°”ê¿ˆ ì œê±°
    text = re.sub(r"\s+", " ", text)                    # ì—°ì† ê³µë°± 1ê°œë¡œ ì¶•ì†Œ
    text = text.replace('"', '\\"')                     # í°ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
    text = re.sub(r"[\x00-\x1f\x7f]", "", text)         # ì œì–´ë¬¸ì ì œê±°
    return text.strip()

# (1) ê³µí†µ ìš”ì²­ ìŠ¤í‚¤ë§ˆ
class ParseIRRequest(BaseModel):
    text: str


# (2) ë„ë©”ì¸ ìë™ ê°ì§€ í•¨ìˆ˜
def detect_domain_via_llm(text: str) -> str:
    prompt = f"""
    ë„ˆëŠ” ì…ë ¥ ë¬¸ì¥ì´ ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜/AI ê°œë…ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ë„ë©”ì¸ ê°ì§€ê¸°ì•¼.
    ê°€ëŠ¥í•œ ë„ë©”ì¸ ëª©ë¡:
    ["cnn_param", "sorting", "transformer", "diffusion", "rnn", "cache", "math"]

    - CNN ê´€ë ¨ (ì»¤ë„, stride, padding ë“±) â†’ cnn_param
    - ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ (ë²„ë¸”, ì„ íƒ, ì‚½ì…, quick sort ë“±) â†’ sorting
    - Transformer / attention / QKV â†’ transformer
    - Diffusion / noise / denoising / sampling â†’ diffusion
    - RNN / LSTM / sequence â†’ rnn
    - ìºì‹œ, FIFO, LRU, queue â†’ cache
    - ìˆ˜í•™ì  ê³„ì‚°, ë¯¸ë¶„, í–‰ë ¬, í™•ë¥  â†’ math

    ë¬¸ì¥: "{text}"

    ìœ„ ë¬¸ì¥ì˜ ë„ë©”ì¸ ì´ë¦„ë§Œ í•˜ë‚˜ ì¶œë ¥í•´.
    """
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        temperature=0,
        messages=[
            {"role": "system", "content": "You are a strict domain classifier."},
            {"role": "user", "content": prompt}
        ]
    )
    return resp.choices[0].message.content.strip()


# (3) CNN ì „ìš© íŒŒì´í”„ë¼ì¸
@app.post("/parse_ir")
async def parse_ir(req: ParseIRRequest):
    text = sanitize_input_text(req.text)
    domain = detect_domain_via_llm(text)

    # CNN ë„ë©”ì¸ë§Œ ì—¬ê¸°ì„œ ì²˜ë¦¬
    if domain != "cnn_param":
        return {"error": f"This route handles only CNN. Detected domain: {domain}"}

    ir = call_llm_domain_ir(domain, text)


    cnn_ir = ir["ir"]
    cnn_cfg = cnn_ir.get("params", {})
    basename = ir.get("basename", "cnn_forward_param")
    out_format = ir.get("out_format", "mp4")

    video_path = render_cnn_matrix(cnn_cfg, out_basename=basename, fmt=out_format)
    return {"ir": ir, "video_path": video_path}


# (4) ë²”ìš© ì• ë‹ˆë©”ì´ì…˜ íŒŒì´í”„ë¼ì¸
@app.post("/generate")
async def generate_visualization(req: ParseIRRequest):
    user_text = req.text

    # 1ï¸âƒ£ ìì—°ì–´ â†’ pseudocode IR
    pseudo_ir = call_llm_pseudocode_ir(user_text)

    # 2ï¸âƒ£ pseudocode â†’ structured animation IR
    anim_ir = call_llm_anim_ir(pseudo_ir)

    # 3ï¸âƒ£ animation IR â†’ Manim ì½”ë“œ ìƒì„±
    manim_code = call_llm_codegen(anim_ir)

    # 4ï¸âƒ£ ì½”ë“œ ì €ì¥ + ë Œë”ë§
    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as tmp:
        tmp.write(manim_code)
        tmp_path = tmp.name

    subprocess.run(["manim", "-ql", tmp_path, "AlgorithmScene", "--format", "mp4"])

    return {
        "pseudocode_ir": pseudo_ir,
        "anim_ir": anim_ir,
        "message": "ğŸ¬ Visualization generation started successfully!"
    }
